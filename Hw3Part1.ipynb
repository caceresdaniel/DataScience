{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all the packages needed for scikit-learn, and so on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the heart dataset and assigning it to a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/caceresdaniel/DataScience/master/Heart_s.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data set into testing and training sets with test size = 0.25 and random state = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Age','RestBP','Chol','RestECG','MaxHR','Oldpeak']\n",
    "\n",
    "x = df[features]\n",
    "\n",
    "y = df['AHD']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25,random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running K nearest neighbors on the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6447368421052632\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "knn.fit(x_train, y_train)\n",
    "y_predict = knn.predict(x_test)\n",
    "\n",
    "knnacc = accuracy_score(y_test, y_predict)\n",
    "\n",
    "print(knnacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Decision tree with random state 5 on the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.618421052631579\n"
     ]
    }
   ],
   "source": [
    "heartDT = DecisionTreeClassifier(random_state=5)\n",
    "\n",
    "heartDT.fit(x_train, y_train)\n",
    "\n",
    "dtPredict = heartDT.predict(x_test)\n",
    "\n",
    "dtacc = accuracy_score(y_test, dtPredict)\n",
    "\n",
    "print(dtacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Logistic Regression on the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7368421052631579\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "heartlogreg = LogisticRegression()\n",
    "\n",
    "heartlogreg.fit(x_train, y_train)\n",
    "\n",
    "logregPredict = heartlogreg.predict(x_test)\n",
    "\n",
    "logregacc = accuracy_score(y_test, logregPredict)\n",
    "\n",
    "print(logregacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E) by looking at the generated accuracys we can see that Logistic Regression gives the best accuracy for this dataset. As for the worst accuracy KNN seems to give the least satisfying result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing OneHotEncoding sadly in a inneficient way because I was unable to figure out how to do it with the tools provided by scikitlearn, basically made arrays for every new column to be later added to the dataframe, for loop that goes through each row to see what value it is and appends to the new columns a binary represintation of the row data, in this case doing it for gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = []\n",
    "fs = []\n",
    "\n",
    "for x in df['Gender']:\n",
    "    if x == 'm':\n",
    "        ms.append(1)\n",
    "        fs.append(0)\n",
    "    elif x == 'f':\n",
    "        ms.append(0)\n",
    "        fs.append(1)\n",
    "        \n",
    "ms = pd.Series(ms)\n",
    "fs = pd.Series(fs)\n",
    "df['m'] = ms.values\n",
    "df['f'] = fs.values\n",
    "\n",
    "del df['Gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same as above but doing it for ChestPain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "typ = []\n",
    "nontyp = []\n",
    "asy = []\n",
    "nonang = []\n",
    "\n",
    "for x in df['ChestPain']:\n",
    "    if x == 'typical':\n",
    "        typ.append(1)\n",
    "        nontyp.append(0)\n",
    "        asy.append(0)\n",
    "        nonang.append(0)\n",
    "    elif x == 'nontypical':\n",
    "        typ.append(0)\n",
    "        nontyp.append(1)\n",
    "        asy.append(0)\n",
    "        nonang.append(0)\n",
    "    elif x == 'nonanginal':\n",
    "        typ.append(0)\n",
    "        nontyp.append(0)\n",
    "        asy.append(0)\n",
    "        nonang.append(1)\n",
    "    elif x =='asymptomatic':\n",
    "        typ.append(0)\n",
    "        nontyp.append(0)\n",
    "        asy.append(1)\n",
    "        nonang.append(0)\n",
    "\n",
    "typ = pd.Series(typ)\n",
    "nontyp = pd.Series(nontyp)\n",
    "asy = pd.Series(asy)\n",
    "nonang = pd.Series(nonang)\n",
    "df['typical'] = typ.values\n",
    "df['nontypical'] = nontyp.values\n",
    "df['asymptomatic'] = asy.values\n",
    "df['nonanginal'] = nonang.values\n",
    "\n",
    "del df['ChestPain']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same as above but doing this for Thal, had to add an aditional else statement because Thal has some missing values represented as NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix = []\n",
    "norm = []\n",
    "rev = []\n",
    "\n",
    "for x in df['Thal']:\n",
    "    if x == 'fixed':\n",
    "        fix.append(1)\n",
    "        norm.append(0)\n",
    "        rev.append(0)\n",
    "    elif x == 'normal':\n",
    "        fix.append(0)\n",
    "        norm.append(1)\n",
    "        rev.append(0)\n",
    "    elif x == 'reversable':\n",
    "        fix.append(0)\n",
    "        norm.append(0)\n",
    "        rev.append(1)\n",
    "    else:\n",
    "        fix.append(0)\n",
    "        norm.append(0)\n",
    "        rev.append(0)\n",
    "        \n",
    "fix = pd.Series(fix)\n",
    "norm = pd.Series(norm)\n",
    "rev = pd.Series(rev)\n",
    "df['fixed'] = fix.values\n",
    "df['normal'] = norm.values\n",
    "df['reversable'] = rev.values\n",
    "\n",
    "del df['Thal']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running KNN on the edited data set that now has OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6710526315789473\n"
     ]
    }
   ],
   "source": [
    "newFeats = ['Age','RestBP','Chol','RestECG','MaxHR','Oldpeak', 'm','f','typical','nontypical','asymptomatic','nonanginal','fixed','normal','reversable']\n",
    "\n",
    "newx = df[newFeats]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(newx, y, test_size=0.25,random_state=4)\n",
    "\n",
    "knn.fit(x_train, y_train)\n",
    "y_predict = knn.predict(x_test)\n",
    "\n",
    "knnacc = accuracy_score(y_test, y_predict)\n",
    "\n",
    "print(knnacc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running decistion tree on the edited data set that now has OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8026315789473685\n"
     ]
    }
   ],
   "source": [
    "xdttrain, xdttest, ydttrain, ydttest = train_test_split(newx, y, test_size=0.25,random_state=5)\n",
    "\n",
    "heartDT.fit(xdttrain, ydttrain)\n",
    "\n",
    "dtPredict = heartDT.predict(xdttest)\n",
    "\n",
    "dtacc = accuracy_score(ydttest, dtPredict)\n",
    "\n",
    "print(dtacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Logistic regression on the edited data set that now has OneHotEncoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8157894736842105\n"
     ]
    }
   ],
   "source": [
    "xlrtrain, xlrtest, ylrtrain, ylrtest = train_test_split(newx, y, test_size=0.25,random_state=4)\n",
    "\n",
    "heartlogreg.fit(xlrtrain, ylrtrain)\n",
    "\n",
    "logregPredict = heartlogreg.predict(xlrtest)\n",
    "\n",
    "logregacc = accuracy_score(ylrtest, logregPredict)\n",
    "\n",
    "print(logregacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G) for each method of testing there was an increase of accuracy the one that had the most increase was Logistic Regression which went from 73% to 81% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Cross-Validation with Decision Tree on the edited data set that now has OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70967742 0.74193548 0.77419355 0.74193548 0.8        0.73333333\n",
      " 0.63333333 0.56666667 0.66666667 0.68965517]\n"
     ]
    }
   ],
   "source": [
    "dtacclist = cross_val_score(heartDT, newx, y, cv=10, scoring='accuracy')\n",
    "print(dtacclist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Logistic Regressionwith Decision Tree on the edited data set that now has OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77419355 0.80645161 0.87096774 0.87096774 0.9        0.66666667\n",
      " 0.8        0.83333333 0.8        0.79310345]\n"
     ]
    }
   ],
   "source": [
    "logregacclist = cross_val_score(heartlogreg, newx, y, cv=10, scoring='accuracy')\n",
    "print(logregacclist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running KNN with Decision Tree on the edited data set that now has OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70967742 0.64516129 0.48387097 0.64516129 0.6        0.46666667\n",
      " 0.66666667 0.66666667 0.53333333 0.72413793]\n"
     ]
    }
   ],
   "source": [
    "knnacclist = cross_val_score(knn, newx, y, cv=10, scoring='accuracy')\n",
    "print(knnacclist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
